{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMART EMAIL CLASSIFIER\n",
    "\n",
    "## Analyze Data\n",
    "The goal of this notebook is to analyze the data.\n",
    "\n",
    "## 1) Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import random\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamulticore import LdaModel as Lda\n",
    "import csv\n",
    "from wordcloud import WordCloud\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.gridspec as gridspec\n",
    "import re\n",
    "import math\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "# from sklearn.manifold import TSNE\n",
    "from gensim.models import Word2Vec \n",
    "from nltk.cluster import KMeansClusterer\n",
    "import nltk\n",
    "from sklearn import cluster\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Functions to load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reading_data(infile):\n",
    "    return [line.rstrip('\\n').split(' ') for line in open(infile, 'r')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Functions to run the clustering models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDA(emails,num_groups,n_sample,plot_LDA,area):\n",
    "    # Creating term dictionary of corpus, where each unique term is assigned an index. \n",
    "    dictionary = corpora.Dictionary(emails)\n",
    "    corpus = [dictionary.doc2bow(text) for text in emails] \n",
    "    # Filter terms which occurs in less than 4 articles & more than 40% of the articles \n",
    "    # dictionary.filter_extremes(no_below=4, no_above=0.4)\n",
    "    # Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "    doc_term_matrix = [dictionary.doc2bow(email) for email in emails]\n",
    "        \n",
    "    # Creating the object for LDA model using gensim library & Training LDA model on the document term matrix.\n",
    "    print('    Running LDA')   \n",
    "    ldamodel = Lda(doc_term_matrix, num_topics=num_groups, id2word = dictionary, passes=50, iterations=500)\n",
    "    \n",
    "#     Saving the model\n",
    "    try:\n",
    "        os.mkdir('../data/analysis')\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        os.mkdir('../data/analysis/LDA')\n",
    "    except:\n",
    "        pass\n",
    "    if area != None:\n",
    "        anadir = '../data/analysis/LDA/%s'%area\n",
    "    else:\n",
    "        anadir = '../data/analysis/LDA/all_areas'\n",
    "    try:\n",
    "        os.mkdir(anadir)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        os.mkdir(anadir+'/%s_groups'%num_groups)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    ldafile = open(anadir+'/%s_groups/lda_model_%semails.pkl'%(num_groups,n_sample),'wb')\n",
    "    pickle.dump(ldamodel,ldafile)\n",
    "    ldafile.close()\n",
    " \n",
    "    \n",
    "    # Save all the words and frequencies for each topic    \n",
    "    with open(anadir+'/%s_groups/all_groups.csv'%num_groups, 'w', newline='') as g:\n",
    "        for i,topic in enumerate(ldamodel.print_topics(num_topics=num_groups, num_words=100)):\n",
    "            with open(anadir+'/%s_groups/group_%s_with_freqs.csv'%(num_groups,i), 'w', newline='') as f:\n",
    "                words = topic[1].split(\"+\")\n",
    "                f.write(\",\".join(words))\n",
    "                words_nofreqs = [word.split(\"*\")[1].replace(' ','').replace('\"','') for word in topic[1].split(\"+\")]\n",
    "                g.write(\" \".join(words_nofreqs)+'\\n')\n",
    "                \n",
    "    clusters = [line.strip('\\n') for line in open(anadir+'/%s_groups/all_groups.csv'%num_groups)]\n",
    "    for i in range(num_groups):\n",
    "        for j in range(num_groups):\n",
    "             if i < j:\n",
    "                    print('       Similarity between group %s and %s'%(i+1,j+1),get_jaccard_sim(clusters[i], clusters[j]))\n",
    "           \n",
    "    if plot_LDA == True:\n",
    "        print('    Plotting LDA results')\n",
    "        plotting_LDA(ldamodel,num_groups, doc_term_matrix, dictionary, area)\n",
    "    return ldamodel\n",
    "\n",
    "def load_LDA_model(emails,num_groups,n_sample,plot_LDA,area):\n",
    "    if area != None:\n",
    "        ldafolder = '../data/analysis/LDA/%s'%area\n",
    "    else:\n",
    "        ldafolder = '../data/analysis/LDA/all_areas'\n",
    "    ldamodel = pickle.load(open(ldafolder+'/%s_groups/lda_model_%semails.pkl'%(num_groups,n_sample), 'rb'))\n",
    "    if plot_LDA == True:\n",
    "        dictionary = corpora.Dictionary(emails)\n",
    "        corpus = [dictionary.doc2bow(text) for text in emails] \n",
    "        # Filter terms which occurs in less than 4 articles & more than 40% of the articles \n",
    "        # dictionary.filter_extremes(no_below=4, no_above=0.4)\n",
    "        # Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "        doc_term_matrix = [dictionary.doc2bow(email) for email in emails]\n",
    "        plotting_LDA(ldamodel,num_groups, doc_term_matrix, dictionary, area)\n",
    "#     clusters = [line.strip('\\n') for line in open(ldafolder+'/%s_groups/all_groups.csv'%num_groups)]\n",
    "#     for i in range(num_groups):\n",
    "#         for j in range(num_groups):\n",
    "#              if i < j:\n",
    "#                     print('       Similarity between group %s and %s'%(i+1,j+1),get_jaccard_sim(clusters[i], clusters[j]))\n",
    "    \n",
    "\n",
    "    return ldamodel\n",
    "\n",
    "def get_jaccard_sim(str1, str2): \n",
    "    # This function measures the similarity between two texts\n",
    "    a = set(str1.split()) \n",
    "    b = set(str2.split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "def Kmeans_TFIDF(emails_clean,n_clusters,plot_Kmeans,area):\n",
    "    print('  Running K-means clustering using TF-IDF')\n",
    "    df_clean = pd.DataFrame(columns=['message'])\n",
    "    for email in emails_clean:\n",
    "            df_clean = df_clean.append(pd.DataFrame({'message':[' '.join(email)]}))\n",
    "    vect = TfidfVectorizer(analyzer='word',lowercase = False, max_df=0.3, min_df=2)\n",
    "\n",
    "    X = vect.fit_transform(df_clean['message'])\n",
    "    features = vect.get_feature_names()\n",
    "    batch_size = 500\n",
    "    clf = MiniBatchKMeans(n_clusters=n_clusters, init_size=1000, batch_size=batch_size, max_iter=100)  \n",
    "    clf.fit(X)\n",
    "    labels = clf.fit_predict(X)\n",
    "    if plot_Kmeans == True:\n",
    "        print('   Plotting results from K-means clustering')\n",
    "        plot_tfidf_classfeats_h(top_feats_per_cluster(X, labels, features, 0.1, 10),area,num_groups)\n",
    "        if area!= None:\n",
    "            # We comment the next one as it kills the kernel, too much memory to plot all the points (one per mail)\n",
    "            plot_Kmeans_PCA(X, clf, labels, features, area, num_groups)\n",
    "            \n",
    "def Kmeans_word2vec(sentences,n_clusters,plot_Kmeans,area):\n",
    "    print('  Running K-means clustering using word embeddings')\n",
    "    model = Word2Vec(sentences, min_count=1)\n",
    "     \n",
    "    # get vector data\n",
    "    X = model[model.wv.vocab]\n",
    "    kclusterer = KMeansClusterer(n_clusters, distance=nltk.cluster.util.cosine_distance, repeats=25)\n",
    "    assigned_clusters = kclusterer.cluster(X, assign_clusters=True)\n",
    "     \n",
    "    words = list(model.wv.vocab)\n",
    "    for i, word in enumerate(words):  \n",
    "        print (word + \":\" + str(assigned_clusters[i]))  \n",
    "    kmeans = cluster.KMeans(n_clusters=n_clusters)\n",
    "    kmeans.fit(X)     \n",
    "    labels = kmeans.labels_\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    if plot_Kmeans == True:\n",
    "        print('   Plotting results from K-means clustering')\n",
    "        plot_tfidf_classfeats_h(top_feats_per_cluster(X, labels, features, 0.1, 10),area,num_groups)\n",
    "        if area!= None:\n",
    "            # We comment the next one as it kills the kernel, too much memory to plot all the points (one per mail)\n",
    "#             plot_Kmeans_PCA(X, clf, labels, features, area, n_clusters)            \n",
    "             print('    Finished plotting')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Functions to visualize the output clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_LDA(ldamodel,num_groups, doc_term_matrix, dictionary,area):\n",
    "    # Plotting the first 9 groups\n",
    "    height=1+3*math.ceil(num_groups/3)\n",
    "    fig = plt.figure(figsize=(18.,height))\n",
    "    nh, nv = 3,math.ceil(num_groups/3)\n",
    "    gs = gridspec.GridSpec(nv, nh)  \n",
    "    i_plot=0\n",
    "    for t in range(num_groups):\n",
    "        ax = fig.add_subplot(gs[int(i_plot / nh), i_plot % nh])\n",
    "        ax.imshow(WordCloud().fit_words(dict(ldamodel.show_topic(t, 100))))\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_title(\"Topic %s\"%t)\n",
    "        i_plot += 1\n",
    "    try:\n",
    "        os.mkdir('../figures')\n",
    "    except:\n",
    "        pass\n",
    "    if area != None:\n",
    "        figdir = '../figures/%s'%area\n",
    "    else:\n",
    "        figdir = '../figures'\n",
    "    try:\n",
    "        os.mkdir(figdir)\n",
    "    except:\n",
    "        pass\n",
    "    plt.savefig(figdir+'/wordclouds_%sgroups.pdf'%num_groups, bbox_inches='tight',dpi=72)\n",
    "    data = pyLDAvis.gensim.prepare(ldamodel, doc_term_matrix, dictionary)\n",
    "    pyLDAvis.enable_notebook()\n",
    "    pyLDAvis.save_html(data, figdir+'/lda_%sgroups.html'%num_groups)\n",
    "\n",
    "\n",
    "\n",
    "def plot_tfidf_classfeats_h(dfs,area,num_groups):\n",
    "    if area != None:\n",
    "        figdir = '../figures/%s'%area\n",
    "    else:\n",
    "        figdir = '../figures'\n",
    "    try:\n",
    "        os.mkdir(figdir)\n",
    "    except:\n",
    "        pass\n",
    "    fig = plt.figure(figsize=(15, 9), facecolor=\"w\")\n",
    "    x = np.arange(len(dfs[0]))\n",
    "    for i, df in enumerate(dfs):\n",
    "        ax = fig.add_subplot(1, len(dfs), i+1)\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "        ax.set_frame_on(False)\n",
    "        ax.get_xaxis().tick_bottom()\n",
    "        ax.get_yaxis().tick_left()\n",
    "        ax.set_xlabel(\"Tf-Idf Score\", labelpad=16, fontsize=14)\n",
    "        ax.set_title(\"cluster = %s\"%(i+1), fontsize=16)\n",
    "        ax.ticklabel_format(axis='x', style='sci', scilimits=(-2,2))\n",
    "        ax.barh(x, df.score, align='center', color='#7530FF')\n",
    "        ax.set_yticks(x)\n",
    "        ax.set_ylim([-1, x[-1]+1])\n",
    "        yticks = ax.set_yticklabels(df.features)\n",
    "        plt.subplots_adjust(bottom=0.09, right=0.97, left=0.15, top=0.95, wspace=0.52)\n",
    "    plt.savefig(figdir+'/tfidf_%sgroups.pdf'%num_groups, bbox_inches='tight',dpi=72)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_Kmeans_PCA(X, clf, labels, features, area, num_groups):\n",
    "    X_dense = X.todense()\n",
    "    pca = PCA(n_components=2).fit(X_dense)\n",
    "    coords = pca.transform(X_dense)\n",
    "    label_colors = [\"#2AB0E9\", \"#2BAF74\", \"#D7665E\", \"#CCCCCC\", \n",
    "                \"#D2CA0D\", \"#522A64\", \"#A3DB05\", \"#FC6514\",'#FF3030']\n",
    "    colors = [label_colors[i] for i in labels]\n",
    "    \n",
    "    plt.scatter(coords[:, 0], coords[:, 1], c=colors)\n",
    "    # Plot the cluster centers\n",
    "    centroids = clf.cluster_centers_\n",
    "    centroid_coords = pca.transform(centroids)\n",
    "    plt.scatter(centroid_coords[:, 0], centroid_coords[:, 1], marker='X', s=200, linewidths=2, c=label_colors,edgecolors='black')\n",
    "    plt.savefig('../figures/%s/kmeans_tfidf_%sgroups.pdf'%(area,num_groups), bbox_inches='tight',dpi=72)\n",
    "    plt.show()\n",
    "\n",
    "def top_tfidf_feats(row, features, top_n=20):\n",
    "    topn_ids = np.argsort(row)[::-1][:top_n]\n",
    "    top_feats = [(features[i], row[i]) for i in topn_ids]\n",
    "    df = pd.DataFrame(top_feats, columns=['features', 'score'])\n",
    "    return df\n",
    "\n",
    "def top_feats_in_doc(X, features, row_id, top_n=25):\n",
    "    row = np.squeeze(X[row_id].toarray())\n",
    "    return top_tfidf_feats(row, features, top_n)\n",
    "\n",
    "def top_mean_feats(X, features, grp_ids=None, min_tfidf=0.1, top_n=25):\n",
    "    if grp_ids:\n",
    "        D = X[grp_ids].toarray()\n",
    "    else:\n",
    "        D = X.toarray()\n",
    "\n",
    "    D[D < min_tfidf] = 0\n",
    "    tfidf_means = np.mean(D, axis=0)\n",
    "    return top_tfidf_feats(tfidf_means, features, top_n)\n",
    "        \n",
    "def top_feats_per_cluster(X, y, features, min_tfidf=0.1, top_n=25):\n",
    "    dfs = []\n",
    "    labels = np.unique(y)\n",
    "    for label in labels:\n",
    "        ids = np.where(y==label) \n",
    "        feats_df = top_mean_feats(X, features, ids, min_tfidf=min_tfidf, top_n=top_n)\n",
    "        feats_df.label = label\n",
    "        dfs.append(feats_df)\n",
    "    return dfs   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    by_area = False\n",
    "    \n",
    "    run_LDA = False\n",
    "    load_LDA = False\n",
    "    plot_LDA = False\n",
    "    \n",
    "    run_TFIDF = False\n",
    "    run_embeddings = True\n",
    "    plot_Kmeans = True\n",
    "\n",
    "    \n",
    "    num_groups = 9    # number of clusters for the unsupervised clustering\n",
    "\n",
    "    \n",
    "    if by_area == True:\n",
    "        for area in ['Trade','Legal','Risk','Finance','Business','Government','Energy','Admin','OperatingOfficer','HR','Logistics']:\n",
    "            print('\\nAnalizing area %s'%area)\n",
    "            infile = \"../data/preprocessed/preprocessed_%s_pos.csv\"%area\n",
    "            emails_clean = reading_data(infile)\n",
    "            n_sample = len(emails_clean)\n",
    "            if run_LDA == True:\n",
    "                ldamodel = LDA(emails_clean,num_groups,n_sample,plot_LDA,area)\n",
    "            if load_LDA == True:\n",
    "                ldamodel = load_LDA_model(emails_clean,num_groups,n_sample,plot_LDA,area)\n",
    "            if run_TFIDF == True:\n",
    "                Kmeans_TFIDF(emails_clean,num_groups,plot_Kmeans,area)\n",
    "            if run_embeddings == True:\n",
    "                Kmeans_word2vec(emails_clean,num_groups,plot_Kmeans,area)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "    else:\n",
    "        infile = \"../data/preprocessed/preprocessed_pos.csv\"\n",
    "        emails_clean = reading_data(infile)\n",
    "        n_sample = len(emails_clean)\n",
    "        area = None    \n",
    "        if run_LDA == True:\n",
    "            ldamodel = LDA(emails_clean,num_groups,n_sample,plot_LDA,area)\n",
    "        if load_LDA == True:\n",
    "            ldamodel = load_LDA_model(emails_clean,num_groups,n_sample,plot_LDA,area)\n",
    "        if run_TFIDF == True:\n",
    "            Kmeans_TFIDF(emails_clean,num_groups,plot_Kmeans,area)\n",
    "        if run_embeddings == True:\n",
    "            Kmeans_word2vec(emails_clean,num_groups,plot_Kmeans,area)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
