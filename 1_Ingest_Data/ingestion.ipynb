{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMART EMAIL CLASSIFIER\n",
    "\n",
    "# Ingest Data\n",
    "In this notebook I am going to explore and ingest the ENRON email dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import codecs\n",
    "from tqdm import tqdm\n",
    "import email\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Explore the ENRON data structure\n",
    "- We check how the emails are distributed in folders etc.\n",
    "- We see that there are 150 folders (each one corresponding to one person).\n",
    "- We see that inside the folder 'stockley-c', there is a folder called 'Christian Stockley\", so we manually move all the subfolders 'stockley-c'\n",
    "- We also see that in the ingestion, we should not include the hidden files created by MAC \".DS_Store\"\n",
    "- The folder (tree) structure is different for each person (i.e., different depths per user).\n",
    "- We take into account the coding, which is 'ISO-8859-15'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_email_by_path(path):\n",
    "# Function to read one file/email and print its content\n",
    "    with codecs.open(path,'r','ISO-8859-1') as f:\n",
    "        content = f.read()\n",
    "        print(content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Ingest the data\n",
    "We write the functions that will be called afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir='../data/maildir'\n",
    "\n",
    "\n",
    "def folder_to_df_tree(path):\n",
    "# Reads one file and creates a dataframe with one column per information about the email (recipient, sender, content...)\n",
    "    if not path.endswith(\"DS_Store\"):\n",
    "        with codecs.open(path,'r','ISO-8859-1') as f:\n",
    "            observation = f.read()\n",
    "            msg = email.parser.Parser().parsestr(observation)\n",
    "            return pd.DataFrame({'person':[path.split(datadir)[1].split('/',1)[1].split('/',1)[0]],\n",
    "                                 'directory':[path.split(datadir)[1].split('/',1)[1].split('/',1)[1].rsplit('/',1)[0]],\n",
    "                                 'email_num':[path.split(datadir)[1].split('/',1)[1].split('/',1)[1].rsplit('/',1)[1].split('.')[0]],\n",
    "                                 'email_ID': [msg['Message-ID']],\n",
    "                                 'from': [msg['from']],\n",
    "                                 'to':[msg['to']],\n",
    "                                 'cc':[msg['cc']],\n",
    "                                 'bcc':[msg['bcc']],\n",
    "                                 'subject':[msg['subject']],\n",
    "                                 'date':[pd.to_datetime(msg['Date'])],\n",
    "                                 'message':[msg.get_payload()],\n",
    "                                 'attachment':[msg['X-FileName']]})\n",
    "def folder_to_df_no_tree(path):\n",
    "# Same as folder_to_df_tree but where the email is not inside a folder but in the user's folder\n",
    "    if not path.endswith(\"DS_Store\"):\n",
    "        with codecs.open(path,'r','ISO-8859-1') as f:\n",
    "            observation = f.read()\n",
    "            msg = email.parser.Parser().parsestr(observation)\n",
    "            return pd.DataFrame({'person':[path.split(datadir)[1].split('/',1)[1].split('/',1)[0]],\n",
    "                                 'directory':'parent',\n",
    "                                 'email_num':[path.split(datadir)[1].split('/',1)[1].split('/',1)[1].split('.')[0]],\n",
    "                                 'email_ID': [msg['Message-ID']],\n",
    "                                 'from': [msg['from']],\n",
    "                                 'to':[msg['to']],\n",
    "                                 'cc':[msg['cc']],\n",
    "                                 'bcc':[msg['bcc']],\n",
    "                                 'subject':[msg['subject']],\n",
    "                                 'date':[pd.to_datetime(msg['Date'])],\n",
    "                                 'message':[msg.get_payload()],\n",
    "                                 'attachment':[msg['X-FileName']]})\n",
    "\n",
    "def split_list(alist, wanted_parts=20):\n",
    "# Splits the list alist into different parts\n",
    "    length = len(alist)\n",
    "    return [ alist[i*length // wanted_parts: (i+1)*length // wanted_parts] \n",
    "             for i in range(wanted_parts) ]\n",
    "\n",
    "def reading_files(i,paths):\n",
    "# Creates one dataframe with all the files inside each segment\n",
    "    df = pd.DataFrame(columns=[ 'person', 'to', 'from', 'bcc', 'cc', 'subject','attachment', 'date', 'directory', 'email_ID', 'email_num', 'message'])\n",
    "    for path in tqdm(paths):\n",
    "        try:\n",
    "            df=df.append(folder_to_df_tree(path),sort=True)\n",
    "# If the file is not in a tree structure, it raises an error\n",
    "        except:\n",
    "            df=df.append(folder_to_df_no_tree(path),sort=True)\n",
    "# We save the dataframes for each segment in separate csv files\n",
    "# Please comment the following lines if you don't want the intermediate steps to be saved into the disk\n",
    "    try:\n",
    "        os.mkdir('../data/ingest')\n",
    "    except:\n",
    "        pass \n",
    "    try:\n",
    "        os.mkdir('../data/ingest/groups')\n",
    "    except:\n",
    "        pass \n",
    "    df.to_csv('../data/ingest/groups/out_%s.csv'%i,index_label=False)\n",
    "    print(\"iteration %s finished\"%i)\n",
    "    return df\n",
    "\n",
    "def load_splitted_df(n_thread):\n",
    "#This function recovers the dataframes from the csv splitted\n",
    "    df = pd.DataFrame(columns=[ 'person', 'to', 'from', 'bcc', 'cc', 'subject','attachment', 'date', 'directory', 'email_ID', 'email_num', 'message'])\n",
    "    try:\n",
    "        os.mkdir('../data/ingest/all')\n",
    "    except:\n",
    "        pass          \n",
    "\n",
    "    for i in range(n_thread):\n",
    "        df=df.append(pd.read_csv('../data/ingest/groups/out_%s.csv'%i),sort=True)\n",
    "    df.to_csv('../data/ingest/all/emails.csv',index_label=False)       \n",
    "\n",
    "def load_ingested_df():\n",
    "#This function recovers the final dataframe from email.csv\n",
    "    try:\n",
    "        df=pd.read_csv('../data/ingest/all/emails.csv')\n",
    "        return df\n",
    "    except:\n",
    "        print('Error to read final csv file')          \n",
    "\n",
    "\n",
    "def ingest_data_to_csv():\n",
    "# This function creates emails.csv file with all the emails from all the folders  \n",
    "# Creates one text file with all the email files using the UNIX command find, and saves it to the file paths.txt     \n",
    "    !find ../data/maildir -type f -name \"*.\" > ../data/maildir/paths.txt\n",
    "# Creates a list of paths, each one containing the path for each email  \n",
    "    paths= [line.rstrip('\\n') for line in open('../data/maildir/paths.txt')]\n",
    "# To reduce the memory load, we divide the number of files in n_tread segments, and at the end we want to join them\n",
    "    n_thread=20\n",
    "    paths_splitted=split_list(paths,n_thread)\n",
    "# We multiprocess to speed up the data ingest          \n",
    "    pool = mp.Pool(processes=n_thread)\n",
    "    results = pool.starmap(reading_files, [(i, j) for i, j in enumerate(paths_splitted)]) \n",
    "# We join all the segments, creating one final dataframe and csv file for all the emails\n",
    "    df_final = pd.DataFrame(columns=[ 'person', 'to', 'from', 'bcc', 'cc', 'subject','attachment', 'date', 'directory', 'email_ID', 'email_num', 'message'])\n",
    "    for result in results:\n",
    "        df_final = df_final.append(result,sort=True)\n",
    "    try:\n",
    "        os.mkdir('../data/ingest/all')\n",
    "    except:\n",
    "        pass          \n",
    "\n",
    "    df_final.to_csv('../data/ingest/all/emails.csv',index_label=False)       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message-ID: <20368457.1075860850650.JavaMail.evans@thyme>\r\n",
      "Date: Fri, 1 Jun 2001 12:33:59 -0700 (PDT)\r\n",
      "From: julie.armstrong@enron.com\r\n",
      "To: eric.gadd@enron.com, robert.hayes@enron.com, steven.harris@enron.com, \r\n",
      "\trobert.kilmer@enron.com, kay.miller@enron.com, \r\n",
      "\tdave.neubauer@enron.com, john.millar@enron.com, \r\n",
      "\tkevin.hyatt@enron.com\r\n",
      "Subject: Updated Contact list of Direct Reports for Danny McCarty\r\n",
      "Cc: cindy.stark@enron.com, susan.wadle@enron.com, tammy.kovalcik@enron.com, \r\n",
      "\tmarian.salinas@enron.com, audrey.robertson@enron.com, \r\n",
      "\tzelda.paschal@enron.com, sharon.solon@enron.com, \r\n",
      "\tdeborah.cappiello@enron.com, connie.hook@enron.com\r\n",
      "Mime-Version: 1.0\r\n",
      "Content-Type: text/plain; charset=us-ascii\r\n",
      "Content-Transfer-Encoding: 7bit\r\n",
      "Bcc: cindy.stark@enron.com, susan.wadle@enron.com, tammy.kovalcik@enron.com, \r\n",
      "\tmarian.salinas@enron.com, audrey.robertson@enron.com, \r\n",
      "\tzelda.paschal@enron.com, sharon.solon@enron.com, \r\n",
      "\tdeborah.cappiello@enron.com, connie.hook@enron.com\r\n",
      "X-From: Armstrong, Julie </O=ENRON/OU=NA/CN=RECIPIENTS/CN=NOTESADDR/CN=9351898A-10E9542A-8625684D-4F81A7>\r\n",
      "X-To: Gadd, Eric </O=ENRON/OU=NA/CN=RECIPIENTS/CN=NOTESADDR/CN=6C5E9351-BF35D0C6-86256A25-6D7549>, Hayes, Robert </O=ENRON/OU=NA/CN=RECIPIENTS/CN=RHAYES>, Harris, Steven </O=ENRON/OU=NA/CN=RECIPIENTS/CN=NOTESADDR/CN=65B627BC-84E5435E-862566DE-1137EE>, Kilmer III, Robert </O=ENRON/OU=NA/CN=RECIPIENTS/CN=RKILMER>, Miller, Mary Kay </O=ENRON/OU=NA/CN=RECIPIENTS/CN=NOTESADDR/CN=59406CF-4A8787C-862566DE-280AA>, Neubauer, Dave </O=ENRON/OU=NA/CN=RECIPIENTS/CN=NOTESADDR/CN=BBDEDAA6-75C673E4-86256808-5FDC01>, Millar, John </O=ENRON/OU=NA/CN=RECIPIENTS/CN=JMILLAR3>, Hyatt, Kevin </O=ENRON/OU=NA/CN=RECIPIENTS/CN=KHYATT>\r\n",
      "X-cc: Stark, Cindy </O=ENRON/OU=NA/CN=RECIPIENTS/CN=CSTARK>, Wadle, Susan </O=ENRON/OU=NA/CN=RECIPIENTS/CN=SWADLE>, Kovalcik, Tammy </O=ENRON/OU=NA/CN=RECIPIENTS/CN=TKOVALC>, Salinas, Marian </O=ENRON/OU=NA/CN=RECIPIENTS/CN=MSALINA4>, Robertson, Audrey </O=ENRON/OU=NA/CN=RECIPIENTS/CN=AROBERT>, Paschal, Zelda </O=ENRON/OU=NA/CN=RECIPIENTS/CN=ZPASCHA>, Solon, Sharon </O=ENRON/OU=NA/CN=RECIPIENTS/CN=NOTESADDR/CN=FD87026C-BEAAE7C0-86256695-5B8FC7>, Cappiello, Deborah </O=ENRON/OU=NA/CN=RECIPIENTS/CN=DCAPPIE>, Hook, Connie </O=ENRON/OU=NA/CN=RECIPIENTS/CN=CHOOK>\r\n",
      "X-bcc: \r\n",
      "X-Folder: \\Kevin_Hyatt_Mar2002\\Hyatt, Kevin\\Personal\r\n",
      "X-Origin: Hyatt-K\r\n",
      "X-FileName: khyatt (Non-Privileged).pst\r\n",
      "\r\n",
      "Attached please find an updated contact list of Danny McCarty Direct Reports.\n",
      "\n",
      "I am pleased to announce that Susan Wadle has joined our group and will be supporting Eric Gadd and his team. \n",
      "\n",
      "If you have any questions or changes, please call me at x33597.  Thank you.  Enjoy the weekend.\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "# We select whether we want to check an email, read the csv from the splitted database or directly ingest the data    \n",
    "    check_first_email=True\n",
    "    loading_splitted=False\n",
    "    ingest_data=False\n",
    "    check_result=False\n",
    "\n",
    "    \n",
    "    if check_first_email == True:\n",
    "        example='../data/maildir/hyatt-k/personal/20.'   # Change the folder \n",
    "        read_email_by_path(example)\n",
    "    if loading_splitted == True:\n",
    "        load_splitted_df(20)\n",
    "    if ingest_data == True:\n",
    "        ingest_data_to_csv()\n",
    "    if check_result == True:\n",
    "        df=load_ingested_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
